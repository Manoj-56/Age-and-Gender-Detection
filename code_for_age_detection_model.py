# -*- coding: utf-8 -*-
"""Age_And_Gender_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sHCSxlWkfwWg-YTP6svwAw-7K1oAJvA8
"""

import os 
import random as r
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# from tensorflow.keras.models import load_model
import cv2
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten,Conv2D,MaxPool2D,Dropout

# Taking Cats and Dogs images from Drive
one_3 = os.listdir('/content/drive/MyDrive/datasets/face_age/1-3')
four_8 = os.listdir('/content/drive/My Drive/datasets/face_age/4-8')
ten_15 = os.listdir('/content/drive/My Drive/datasets/face_age/10-15')
sixteen_20 = os.listdir('/content/drive/My Drive/datasets/face_age/16-20')
twenty_30 = os.listdir('/content/drive/My Drive/datasets/face_age/20-30')
thirty_40 = os.listdir('/content/drive/My Drive/datasets/face_age/31-40')
fourty_50 = os.listdir('/content/drive/My Drive/datasets/face_age/40-50')
fifty_60 = os.listdir('/content/drive/My Drive/datasets/face_age/50-60')
sixty_70 = os.listdir('/content/drive/My Drive/datasets/face_age/60-70')

len(one_3),len(four_8),len(ten_15),len(sixteen_20),len(twenty_30),len(thirty_40),len(fourty_50),len(fifty_60),len(sixty_70)

data_13 = []
for i in one_3:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/1-3/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_13.append(img)
  except(Exception) as e:
    print(e)

data_48 = []
for i in four_8:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/4-8/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_48.append(img)
  except(Exception) as e:
    print(e)

data_1015 = []
for i in ten_15:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/10-15/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_1015.append(img)
  except(Exception) as e:
    print(e)

data_1620 = []
for i in sixteen_20:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/16-20/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_1620.append(img)
  except(Exception) as e:
    print(e)

data_2030 = []
for i in twenty_30:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/20-30/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_2030.append(img)
  except(Exception) as e:
    print(e)

data_3040 = []
for i in thirty_40:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/31-40/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_3040.append(img)
  except(Exception) as e:
    print(e)

data_4050 = []
for i in fourty_50:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/40-50/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_4050.append(img)
  except(Exception) as e:
    print(e)

data_5060 = []
for i in fifty_60:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/50-60/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_5060.append(img)
  except(Exception) as e:
    print(e)

data_6070 = []
for i in sixty_70:
  try:
    img1 =  cv2.imread(f'/content/drive/MyDrive/datasets/face_age/60-70/{i}')
    img2 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
    img = cv2.resize(cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY),(256,256))
    data_6070.append(img)
  except(Exception) as e:
    print(e)

# adding label value to images
lab_13 = list(zip(data_13,[0 for x in range(len(data_13))]))
lab_48 = list(zip(data_48,[1 for x in range(len(data_48))]))
lab_1015 = list(zip(data_1015,[2 for x in range(len(data_1015))]))
lab_1620 = list(zip(data_1620,[3 for x in range(len(data_1620))]))
lab_2030 = list(zip(data_2030,[4 for x in range(len(data_2030))]))
lab_3040 = list(zip(data_3040,[5 for x in range(len(data_3040))]))
lab_4050 = list(zip(data_4050,[6 for x in range(len(data_4050))]))
lab_5060 = list(zip(data_5060,[7 for x in range(len(data_5060))]))
lab_6070 = list(zip(data_6070,[8 for x in range(len(data_6070))]))

data = []
data.extend(lab_13)
data.extend(lab_48)
data.extend(lab_1015)
data.extend(lab_2030)
data.extend(lab_3040)
data.extend(lab_4050)
data.extend(lab_5060)
data.extend(lab_6070)
r.shuffle(data) # shuffling the Data
len(data)
# data

train_fea = []
train_lab = []

valid_fea = []
valid_lab = []

test_fea = []
test_lab = []

for i in range(int(3342*0.75)): # taking 75% Data for traing
  train_fea.append(data[i][0])
  train_lab.append(data[i][1])
for j in range(int(3342*0.75),int(3342*0.75)+int(3342*0.05)): # taking 5% Data for validation
  valid_fea.append(data[j][0])
  valid_lab.append(data[j][1])
for k in range(int(3342*0.75)+int(3342*0.05),3342): # taking 20% Data for Testing
  test_fea.append(data[k][0])
  test_lab.append(data[k][1])

print('train_fea :',len(train_fea))
print('train_lab :',len(train_lab))
print('valid_fea :',len(valid_fea))
print('valid_lab :',len(valid_lab))
print('test_fea :',len(test_fea))
print('test_lab :',len(test_lab))

# Coverting Into Numpy Arrays

train_fea = np.array(train_fea)
train_lab = np.array(train_lab)

valid_fea = np.array(valid_fea)
valid_lab = np.array(valid_lab)

test_fea = np.array(test_fea)
test_lab = np.array(test_lab)

train_fea.shape

# reshaping features
train_fea = train_fea.reshape((train_fea.shape[0],256,256,1))
valid_fea = valid_fea.reshape((valid_fea.shape[0],256,256,1))
test_fea = test_fea.reshape((test_fea.shape[0],256,256,1))

train_fea.shape

# Creating Neural Network 
model = Sequential()
model.add(Conv2D(64,(3,3),input_shape = (256,256,1)))
model.add(MaxPool2D((2,2)))
# model.add(Dropout(0.2))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(MaxPool2D((2,2)))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(32,activation='relu'))
model.add(Dense(9,activation = 'softmax'))
model.summary()

#Compiling
model.compile(optimizer='adam',
              loss = 'sparse_categorical_crossentropy',  
              metrics = ['accuracy'])

model_checkpoint=tf.keras.callbacks.ModelCheckpoint('Detecting_Age_Model.h5',save_best_only=True)

epoch = model.fit(train_fea,train_lab,epochs=20,batch_size = 256,validation_data=(valid_fea,valid_lab),verbose=1)

model.save('Detecting_Age.h5')

model_checkpoint

def prediction(x):
#   read = cv2.imread(x)
  color = cv2.cvtColor(x,cv2.COLOR_BGR2RGB)
  size = cv2.resize((cv2.cvtColor(color,cv2.COLOR_RGB2GRAY)),(256,256))
  image = np.array(size)
  res_img = image.reshape(1,256,256,1)
  pre = model.predict(res_img)
  return pre

import cv2
import numpy as np
from tensorflow.keras.models import load_model
# Load the cascade
face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/DL/haarcascade_frontalface_default.xml')
model = load_model(r'Detecting_Age.h5')

# To capture video from webcam. 
cap = cv2.VideoCapture(0)
# To use a video file as input 
# cap = cv2.VideoCapture('filename.mp4')

while True:
    # Read the frame
    _, img = cap.read()

    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Detect the faces
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)

    # Draw the rectangle around each face
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)
        roi_clr = img[y:y+h,x:x+w]
        predict = prediction(roi_clr)
        if np.argmax(predict) == 0:
            cv2.putText(img,'1-3',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==1:
            cv2.putText(img,'4-8',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==2:
            cv2.putText(img,'10-15',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==3:
            cv2.putText(img,'16-20',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==4:
            cv2.putText(img,'20-30',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==5:
            cv2.putText(img,'31-40',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==6:
            cv2.putText(img,'40-50',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==7:
            cv2.putText(img,'50-60',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)
        elif np.argmax(predict)==8:
            cv2.putText(img,'60-70',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.6,(0,255,0),2)

    # Display
    cv2.imshow('img', img)

    # Stop if escape key is pressed
    k = cv2.waitKey(30) & 0xff
    if k==27:
        break
        
# Release the VideoCapture object
cap.release()

